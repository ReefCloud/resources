[
  {
    "objectID": "Analyses.html",
    "href": "Analyses.html",
    "title": "Data Analyses in R",
    "section": "",
    "text": "This page collated a series of vignettes and tutorials that illustrate brief examples on how to perform analyses relevant to provide interpretation of monitoring data from ReefCloud or other sources."
  },
  {
    "objectID": "Collection.html",
    "href": "Collection.html",
    "title": "Collection",
    "section": "",
    "text": "Phototransect methodology\n\n\n&lt;div class=\"card-header\" id=\"headingOne\"&gt;\n  &lt;h5 class=\"mb-0\"&gt;\n    &lt;button class=\"btn btn-link\" type=\"button\" data-toggle=\"collapse\" data-target=\"#collapseOne\" aria-expanded=\"true\" aria-controls=\"collapseOne\"&gt;\n      Collapsible Group Item #1\n    &lt;/button&gt;\n  &lt;/h5&gt;\n&lt;/div&gt;\n\n&lt;div id=\"collapseOne\" class=\"collapse show\" aria-labelledby=\"headingOne\" data-parent=\"#accordionExample\"&gt;\n  &lt;div class=\"card-body\"&gt;\n    Anim pariatur cliche reprehenderit, enim eiusmod high life accusamus terry richardson ad squid. 3 wolf moon officia aute, non cupidatat skateboard dolor brunch. Food truck quinoa nesciunt laborum eiusmod. Brunch 3 wolf moon tempor, sunt aliqua put a bird on it squid single-origin coffee nulla assumenda shoreditch et. Nihil anim keffiyeh helvetica, craft beer labore wes anderson cred nesciunt sapiente ea proident. Ad vegan excepteur butcher vice lomo. Leggings occaecat craft beer farm-to-table, raw denim aesthetic synth nesciunt you probably haven't heard of them accusamus labore sustainable VHS.\n  &lt;/div&gt;\n&lt;/div&gt;\n\n\n&lt;div class=\"card-header\" id=\"headingTwo\"&gt;\n  &lt;h5 class=\"mb-0\"&gt;\n    &lt;button class=\"btn btn-link collapsed\" type=\"button\" data-toggle=\"collapse\" data-target=\"#collapseTwo\" aria-expanded=\"false\" aria-controls=\"collapseTwo\"&gt;\n      Collapsible Group Item #2\n    &lt;/button&gt;\n  &lt;/h5&gt;\n&lt;/div&gt;\n&lt;div id=\"collapseTwo\" class=\"collapse\" aria-labelledby=\"headingTwo\" data-parent=\"#accordionExample\"&gt;\n  &lt;div class=\"card-body\"&gt;\n    Anim pariatur cliche reprehenderit, enim eiusmod high life accusamus terry richardson ad squid. 3 wolf moon officia aute, non cupidatat skateboard dolor brunch. Food truck quinoa nesciunt laborum eiusmod. Brunch 3 wolf moon tempor, sunt aliqua put a bird on it squid single-origin coffee nulla assumenda shoreditch et. Nihil anim keffiyeh helvetica, craft beer labore wes anderson cred nesciunt sapiente ea proident. Ad vegan excepteur butcher vice lomo. Leggings occaecat craft beer farm-to-table, raw denim aesthetic synth nesciunt you probably haven't heard of them accusamus labore sustainable VHS.\n  &lt;/div&gt;\n&lt;/div&gt;\n\n\n&lt;div class=\"card-header\" id=\"headingThree\"&gt;\n  &lt;h5 class=\"mb-0\"&gt;\n    &lt;button class=\"btn btn-link collapsed\" type=\"button\" data-toggle=\"collapse\" data-target=\"#collapseThree\" aria-expanded=\"false\" aria-controls=\"collapseThree\"&gt;\n      Collapsible Group Item #3\n    &lt;/button&gt;\n  &lt;/h5&gt;\n&lt;/div&gt;\n&lt;div id=\"collapseThree\" class=\"collapse\" aria-labelledby=\"headingThree\" data-parent=\"#accordionExample\"&gt;\n  &lt;div class=\"card-body\"&gt;\n    Anim pariatur cliche reprehenderit, enim eiusmod high life accusamus terry richardson ad squid. 3 wolf moon officia aute, non cupidatat skateboard dolor brunch. Food truck quinoa nesciunt laborum eiusmod. Brunch 3 wolf moon tempor, sunt aliqua put a bird on it squid single-origin coffee nulla assumenda shoreditch et. Nihil anim keffiyeh helvetica, craft beer labore wes anderson cred nesciunt sapiente ea proident. Ad vegan excepteur butcher vice lomo. Leggings occaecat craft beer farm-to-table, raw denim aesthetic synth nesciunt you probably haven't heard of them accusamus labore sustainable VHS.\n  &lt;/div&gt;\n&lt;/div&gt;"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Resources",
    "section": "",
    "text": "Overview\n\n\n\nA brief video introduction to walk you through the ReefCloud features from start to end\n\n\nRead more\n\n\n\n\n\n\n\n\nCollecting photos\n\n\n\nA methodological guide you on designing your monitoring program and collecting data to analyse in ReefCloud\n\n\nComing Soon\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing ReefCloud\n\n\n\nA step-by-step guide to using ReefCloud for analysing coral reef monitoring data\n\n\nRead More.\n\n\n\n\n\n\n\nVideo Resources\n\n\n\nA collection of short videos to guide you on how to perform specific tasks in ReefCloud\n\n\nRead more\n\n\n\n\n\n\n\n\n\n\n\n\n\nFAQs\n\n\n\nFrequently Asked Questions about ReefCloud\n\n\nComing Soon\n\n\n\n\n\n\n\n\n\n\nData Analysis in R\n\n\n\nTutorials and code snippets to guide you, step-by-step, on monitoring data analyses using R language.\n\n\nRead more"
  },
  {
    "objectID": "index.html#here-you-can-find",
    "href": "index.html#here-you-can-find",
    "title": "About this page",
    "section": "",
    "text": "How-to videos\nR code examples\nTemplates\nPresentations"
  },
  {
    "objectID": "projects.html#project-2",
    "href": "projects.html#project-2",
    "title": "Projects",
    "section": "Project 2",
    "text": "Project 2"
  },
  {
    "objectID": "projects.html#project-3",
    "href": "projects.html#project-3",
    "title": "Projects",
    "section": "Project 3",
    "text": "Project 3"
  },
  {
    "objectID": "Reporting.html",
    "href": "Reporting.html",
    "title": "Reporting",
    "section": "",
    "text": "Template 1"
  },
  {
    "objectID": "Vignette_extract_ACA_habitats.html",
    "href": "Vignette_extract_ACA_habitats.html",
    "title": "Extract Habitat Classification from the Allen Coral Atlas",
    "section": "",
    "text": "Warning\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n\n\n\n\n\nGeomorphicBenthicFurther information"
  },
  {
    "objectID": "Vignette_extract_ACA_habitats.html#dataset-description",
    "href": "Vignette_extract_ACA_habitats.html#dataset-description",
    "title": "Extract Habitat Classification from the Allen Coral Atlas",
    "section": "",
    "text": "GeomorphicBenthicFurther information"
  },
  {
    "objectID": "Vignette_extract_ACA_habitats.html#connect-to-the-aca-server",
    "href": "Vignette_extract_ACA_habitats.html#connect-to-the-aca-server",
    "title": "Extract Habitat Classification from the Allen Coral Atlas",
    "section": "Connect to the ACA Server",
    "text": "Connect to the ACA Server\nThe code below allows you to create a connection to the server and explore the available data layers.\n\n\nCode\nlibrary(sf) # simple features packages for handling vector GIS data\nlibrary(httr) # generic webservice package\nlibrary(tidyverse) # a suite of packages for data wrangling, transformation, plotting, ...\nlibrary(ows4R) # interface for OGC webservices\nlibrary(rnaturalearth) #World Map data from Natural Earth\nlibrary(leaflet)\nlibrary(leafem)\nlibrary(knitr)\n\n\n#Base Layer for ACA GeoServer\naca_geo&lt;-\"https://allencoralatlas.org/geoserver/ows\"\n\n# Establish a connection\naca_client &lt;- WFSClient$new(aca_geo, \n                           serviceVersion = \"1.0.0\")\n#List of features\naca_lyrs&lt;-aca_client$getFeatureTypes(pretty = TRUE)\naca_lyrs\n\n\n                                 name                             title\n1    coral-atlas:benthic_data_verbose    Allen Coral Atlas benthic data\n2 coral-atlas:geomorphic_data_verbose Allen Coral Atlas geomorphic data"
  },
  {
    "objectID": "Vignette_extract_ACA_habitats.html#request-data-for-your-monitoring-region",
    "href": "Vignette_extract_ACA_habitats.html#request-data-for-your-monitoring-region",
    "title": "Extract Habitat Classification from the Allen Coral Atlas",
    "section": "Request data for your monitoring region",
    "text": "Request data for your monitoring region\nLet’s assume I have two monitoring sites (i.e., locations) in Palau, and I want to extract the geomorphic habitat classification for these sites. The code below allows you to generate your sites and create a bounding box to delineate the spatial extent of your monitoring and query the GeoServer.\n\n\nCode\nurl &lt;- parse_url(aca_geo)\n\n#Generate sites \nsites&lt;- data.frame(x=c(134.35, 134.43), y=c(7.42,7.28))%&gt;%\n  as.matrix() %&gt;%\n  st_multipoint() %&gt;% \n  st_sfc(crs=4326) %&gt;% \n  st_cast('POINT') %&gt;%\n  st_sf(name=c(\"Site1\", \"Site2\"))\n\n# create a bounding box for a spatial query.\nmy.bbox&lt;-st_bbox(st_buffer(sites,dist = 0.1))\n\nleaflet()%&gt;%addExtent(data=my.bbox,\n                        color = \"red\", \n                          stroke=T,\n                      weight = 1, \n                      smoothFactor = 0.5,\n                      opacity = 1.0, \n                      fillOpacity = 0.5,\n                      fillColor = NULL,\n                      highlightOptions = highlightOptions(color = \"white\", weight = 2,bringToFront = TRUE))%&gt;%\n  addMarkers(data=sites, label = ~name)%&gt;%\n  addProviderTiles(providers$Esri.WorldImagery)\n\n\n\n\n\n\nUsing this bounding box, we can query the server to extract the geomorphic data within this region. The table below is a simple feature data frame (spatial object) containing all the data stored in the GeoServer for geopmorphic habitat classification within the bounding box.\n\n\nCode\n#convert bounding box into string for the query\nmy.bbox&lt;- my.bbox %&gt;%\n  as.character()%&gt;%\n  paste(.,collapse = ',')\n\n#set up your query\nurl$query &lt;- list(service = \"WFS\",\n                  version = \"1.0.0\",\n                  request = \"GetFeature\",\n                  typename = aca_lyrs$name[2], # I am selecting this layer:\"reefcloud:storm4m_exposure_year_tier\",\n                  bbox = my.bbox,\n                  width=768,\n                  height=330,\n                  srs=\"EPSG%3A4326\",\n                  styles='',\n                  format=\"application/openlayers\")\nrequest &lt;- build_url(url)\n\n#request the data and set up coordinate reference\npalau&lt;- read_sf(request)%&gt;%st_set_crs(4326)\n\n\npal &lt;- colorFactor(\n  palette = \"YlOrRd\",\n  domain = palau$class_name\n)\n\nleaflet(palau)%&gt;%addPolygons(color = \"#444444\", \n                          stroke=F,\n                      weight = 1, \n                      smoothFactor = 0.5,\n                      opacity = 1.0, \n                      fillOpacity = 1,\n                      fillColor = ~pal(as.factor(palau$class_name)),\n                      highlightOptions = highlightOptions(color = \"white\", weight = 2,bringToFront = TRUE))%&gt;%\n  addLegend(\"bottomright\", pal = pal, values = ~as.factor(palau$class_name),\n    title = \"Geomorphic classification &lt;/br&gt; Allen Coral Atlas\",\n    labFormat = labelFormat(),\n    opacity = 1\n  )%&gt;%\n  addMarkers(data=sites, label = ~name)%&gt;%\n  addProviderTiles(providers$Esri.WorldImagery)"
  },
  {
    "objectID": "Vignette_extract_ACA_habitats.html#extract-data-for-monitoring-sites",
    "href": "Vignette_extract_ACA_habitats.html#extract-data-for-monitoring-sites",
    "title": "Extract Habitat Classification from the Allen Coral Atlas",
    "section": "Extract data for monitoring sites",
    "text": "Extract data for monitoring sites\nThe steps above allowed us to download the habitat data within the bounding box. Now the data are loaded in the memory, we want to extract the specific habitat classification for each site. This code intercepts your sites with the habitat layer to produce tabulated data of habitat classification at each site.\n\n\nCode\ndata = st_intersection(st_buffer(sites, 0.0002), palau)%&gt;%st_drop_geometry()%&gt;%\n  dplyr::select(name,class_name)%&gt;%\n  rename(Geomorphic=class_name)\n  \nkable(data,format=\"html\",\n             caption=\"Table 1. Geomophic habitat classification for monitoring sites. Source: Allen Coral Atlas.\",\n            ) \n\n\n\nTable 1. Geomophic habitat classification for monitoring sites. Source: Allen Coral Atlas.\n\n\n\nname\nGeomorphic\n\n\n\n\n2\nSite2\nDeep Lagoon\n\n\n1\nSite1\nInner Reef Flat\n\n\n\n\n\n\n\nNow, you are ready to start your analyses. Enjoy!"
  },
  {
    "objectID": "Vignette_extract_ACA_habitats.html#notes",
    "href": "Vignette_extract_ACA_habitats.html#notes",
    "title": "Extract Habitat Classification from the Allen Coral Atlas",
    "section": "Notes",
    "text": "Notes"
  },
  {
    "objectID": "Vignette_extract_RC_covariates.html",
    "href": "Vignette_extract_RC_covariates.html",
    "title": "Environmental data in ReefCloud",
    "section": "",
    "text": "ReefCloud offers access to environmental data layers used for statistical data integration in our Dashboard. The statistical integration models the spatial and temporal series of coral and macroalgae cover across geographies. This allows the creation of summaries on the status and trends of coral reefs at management scales from individual monitoring observations. The figure below shows the outputs from the statistical integration of monitoring data from various institutions across more than 400 sites monitored between 2004 and 2022 (click on the figure to visualise the data in the ReefCloud dashboard).\n\n\n\nTemporal trends of coral cover in the Central Southern Great Barrier Reef\n\n\nEnvironmental data from major disturbances are used as co-variates to explain the variability in the observed changes in coral and macroalgae cover. Currently, there are two environmental datasets available in ReefCloud through our GeoServer:\n\nIncluding environmental co-variates in statistical analyses of coral cover trends can help explain the observed patterns (see figure below, hyperlinked to the ReefCloud Dashboard). While these analyses are automatically generated and available in ReefCloud from the integration of all publically available coral reef data in the platform, individual users might be interested on environmental data layers for their own analyses. So, we have made these datasets accessible through our GIS database (GeoServer). The sections below describe how to access these data in R.\n\n\nEnvironmental driver\nMetric\nFrequency\nSource\nReference\n\n\n\n\nTropical Cyclones\nExposure to damaging waves is represented as the cumulative time (hrs) under destructive waves (&gt; 4m height),\nYearly.\nData is integrated across cyclones in a single year. Maximum values are represented.\nWave hydrodynamic modelling from Windfield data generated from cyclone tracks.\nAIMS\n(Puotinen et al. 2016)\n\n\nThermal Stress\nDegree Heating Week (DHW)\nYearly.\nData is integrated across months in a year and represented as the maximum DHW values per year.\nSatellite-derived Sea Surface Temperature.\nNOAA Coral Reef Watch\n(Watch 2013)\n\n\n\n\n\n\nTemporal hard coral cover and environmental disturbances\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe GeoServer allows free access to environmental data in ReefCloud, but it is a small server designed for small access queries and low traffic. This means that access requests for large areas (e.g., large EEZs or Regions) will likely time out, rendering the system unresponsive.\nIf you would like access to environmental data from all your monitoring sites across large geographic areas, please get in touch with us at support@reefcloud.ai.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe datasets mentioned above are only available for those countries or territories with public monitoring data in ReefCloud. If you are interested in a region where data is not available, please get in touch with us at support@reefcloud.ai\n\n\n\n\n\n\n\nIntroductionData sourceFrequency of updatesLimitationsFurther reading\n\n\nFirst observed in the early 1980s, mass coral bleaching has become one of the most visible and damaging marine ecological impacts of climate change. When the water temperature is above the average maximum summer temperature for extended periods, corals can become thermally stressed, leading to coral bleaching and, eventually, loss of coral. Bleaching is the process by which corals lose the symbiotic algae (zooxanthellae), giving them their distinctive colours and main energy sources. If a coral is severely bleached, disease and death become likely. Over the past decade, severe coral bleaching has become more extensive, frequent, and intense.\nThe Degree Heating Week (DHW) shows how much heat stress has accumulated in an area over the past 12 weeks (3 months). DHW is a widely used indicator and predictor of coral bleaching and can be estimated from long-term temperature logging and remotely sensed Sea Surface Temperature (SST) data. The units for DHW are “degree C-weeks”, combining the intensity and duration of heat stress into one single number. Based on research at NOAA Coral Reef Watch, when the heat stress reaches four-degree C-weeks, you can expect to see significant coral bleaching, especially in more sensitive species. When heat stress reaches eight C-weeks or higher, widespread bleaching and significant mortality are expected\nThe DHW indicator is calculated by accumulating temperature readings that are more than one degree Celsius over the historical maximum monthly mean temperature for a given location. Thus, if the temperature is 2 °C above the summer maximum for 4 weeks, the corresponding DHW indicator is (2 °C x 4 weeks) 8 DHW. Over time, the thermal stress accumulates over a 12-week sliding window.\n\n\nReefCloud uses NOAA’s Coral Reef Watch products to provide insights on thermal stress exposure for monitored sides. NOAA’s Coral Reef Watch products are widely used and are the longest-running DHW products. For ReefCloud, we use NOAA’s Annual Maximum Degree Heating Week (DHW) indicator: For each year during 1985-2021, and at each location, NOAA provides the highest level of accumulated heat stress exposure, measured by Coral Reef Watch’s daily global 5km satellite coral bleaching DHW product. Values are derived using the Version 3.1 daily global 5km CoralTemp satellite sea surface temperature (SST) data product.\n\n\nThermal stress insights on ReefCloud are updated annually as the data becomes available on NOAA Coral Reef Watch.\n\n\nCoral bleaching and subsequent mortality related to DHW will depend on several factors, some of which are related to methodological approaches and additional external factors, as well as the inherent ecological properties of the reef at a given location. While ReefCloud provides a conservative estimation of the exposure of reef systems to thermal anomalies, the observed response to such stress may vary across locations.\nThe NOAA coral reef watch is the most widely used and longest-operating DHW product. The NOAA Coral Reef Watch program estimates the DHW from Sea Surface Temperature (SST) satellite readings at night. While a significant advantage is the validated methodology and global coverage of NOAA’s products, a key challenge with measuring water temperatures from satellites is that clouds obscure the satellite’s view, potentially resulting in large holes in the daily data. During cloudy summer wet seasons, this can result in extended periods, up to several weeks, where there are no new temperature readings, resulting in problems in the estimates of the corresponding DHW product. Hydrodynamic models paired with remotely sensed temperature can estimate temperature even during cloudy conditions. It also provides estimates of DHW at multiple depths, which is not possible with remotely sensed DHW products.\nThe bleaching response to thermal stress and subsequent mortality will also depend on the historical exposure to thermal stress in a location, additional environmental factors (e.g., Light irradiance), and the taxonomic composition of the reef in terms of the physiological susceptibility to different thermal stress thresholds. Furthermore, as reef systems get more exposed to thermal stress, research suggests that natural acclimation or adaptation of reef communities could alter the bleaching response predictions to future temperature anomalies.\n\n\n(Hoegh-Guldberg 1999; Donner 2009; Heron et al. 2016; Guest et al. 2012; Kayanne 2016; Hughes et al. 2018)\n\n\n\n\n\n\n\nIntroductionData sourceMethodsFrequency of updatesLimitations\n\n\nA tropical cyclone is a rapidly rotating storm system with low atmospheric pressure at its calm centre (eye), inward spiralling rainbands, and strong winds forming in sufficiently warm sea surface temperatures in the world’s tropical regions. In the southern hemisphere, these tropical storms are called cyclones and rotate clockwise. In contrast, in the northern hemisphere, cyclones are called hurricanes (western hemisphere) or typhoons (eastern hemisphere) and rotate in an anti-clockwise direction. If sufficiently long-lasting, the extreme winds generated by these storms can build powerful waves, severely damaging coral reefs and shorelines. By modelling where extreme waves could form during a cyclone, it is possible to predict a cyclone ‘damage zone’ beyond which major damage to reefs will not occur.  This zone is defined as the area within which the average height of the top one-third of the waves likely meets or exceeds 4 metres (Hs – significant wave height).  We call this the 4MW (Hs &gt;= 4m) zone.  Field data from 8 past cyclones in the GBR and Western Australia has shown such zones perform well at capturing severe damage – noting that because reef vulnerability is highly variable at &lt;1km scales, some parts of reefs within the damage zone will not be damaged.  Mapping the 4MW cyclone damage zone helps reef managers to:\n\nSpatially target management responses after major tropical cyclones to promote recovery at severely damaged sites.\nIdentify spatial patterns in historical tropical cyclone exposure to explain habitat condition trajectories.\n\n\n\nReefCloud aims to source the most accurate cyclone data for the impacted region. We collate data from various databases to provide the best insights possible. For cyclones within the Australian area of responsibility, we source data provided by the Australian Bureau of Meteorology’s cyclone database, while for the Pacific region, key cyclone data is sourced from the International Best Track Archive for Climate Stewardship. \n\n\nTropical cyclones are remarkably predictable and well-organised storm systems, making it possible to reconstruct the spatial distribution of winds and waves around the eye to build predicted wind and wave ‘fields’ from a short list of input data that is freely available in meteorological databases (location of eye, central and ambient air pressure, size of eye, size of cyclone and cyclone forward speed and direction).  The 4MW damage zone model (Puotinen et al. 2016) first uses this base data to reconstruct the spatial distribution of wind speeds around the cyclone eye every hour along its track.  It then searches in each location across the study area for the locations where wind speeds were sufficiently high and long-lasting to build significant wave heights &gt;= 4m, then counts the number of hours for which such conditions persisted.  The resultant 4MW cyclone damage zone predicts the locations where sufficient wave energy could cause major damage to coral reefs.  Whether or not that damage occurred for a given part of a reef in the damage zone depends on further factors that can be explored in additional work, such as how reefs and islands block the incoming waves and the structural vulnerability of the corals to wave damage.   \nThe 4MW zones provide a useful first step to reconstructing past histories of the relative impact of cyclones versus other disturbances on coral reefs (e.g., (De’ath et al. 2012; Maynard et al. 2015; Darling et al. 2019; Mellin et al. 2019; Vercelloni et al. 2020)). \nCombining the 4MW damage zones with local-scale fetch models and numerical wave models run at a coarser scale allows a more precise estimate of relative wave exposure (e.g., (Ceccarelli et al. 2019; Castro-Sanguino et al. 2021; Price et al. 2021; Gilmour et al. 2019, 2022)). \n\n\nTropical cyclone information is periodically updated once data becomes available on the key cyclone databases being used (BOM, IBTRACS).\n\n\nAs noted above, much work remains to be done to resolve damage patchiness within the 4MW damage zone (Castro-Sanguino et al. 2021). Where sufficient high-resolution bathymetry data exists with access to high-performance computing, numerical wave models can be run to better resolve local scale wave transformation (Puotinen et al. 2020; Callaghan, Mumby, and Mason 2020). Any cyclone wind or wave model is highly sensitive to the quality of the input data recorded in meteorological databases.  These datasets contain missing values and errors.  For ReefCloud, screening methods to correct some of these were implemented (for example, when the size of the eye is recorded to be larger than the size of the overall cyclone – which is impossible).  However, more work remains to be done on this.  Finally, the nature of cyclones and where they track is likely to change as the climate warms, though this remains highly uncertain for most key characteristics of cyclones (Knutson et al. 2019).  Future work will use predicted cyclone tracks from global climate models to examine how wave damage risk to reefs will change."
  },
  {
    "objectID": "Vignette_extract_RC_covariates.html#dataset-description",
    "href": "Vignette_extract_RC_covariates.html#dataset-description",
    "title": "Environmental data in ReefCloud",
    "section": "",
    "text": "IntroductionData sourceFrequency of updatesLimitationsFurther reading\n\n\nFirst observed in the early 1980s, mass coral bleaching has become one of the most visible and damaging marine ecological impacts of climate change. When the water temperature is above the average maximum summer temperature for extended periods, corals can become thermally stressed, leading to coral bleaching and, eventually, loss of coral. Bleaching is the process by which corals lose the symbiotic algae (zooxanthellae), giving them their distinctive colours and main energy sources. If a coral is severely bleached, disease and death become likely. Over the past decade, severe coral bleaching has become more extensive, frequent, and intense.\nThe Degree Heating Week (DHW) shows how much heat stress has accumulated in an area over the past 12 weeks (3 months). DHW is a widely used indicator and predictor of coral bleaching and can be estimated from long-term temperature logging and remotely sensed Sea Surface Temperature (SST) data. The units for DHW are “degree C-weeks”, combining the intensity and duration of heat stress into one single number. Based on research at NOAA Coral Reef Watch, when the heat stress reaches four-degree C-weeks, you can expect to see significant coral bleaching, especially in more sensitive species. When heat stress reaches eight C-weeks or higher, widespread bleaching and significant mortality are expected\nThe DHW indicator is calculated by accumulating temperature readings that are more than one degree Celsius over the historical maximum monthly mean temperature for a given location. Thus, if the temperature is 2 °C above the summer maximum for 4 weeks, the corresponding DHW indicator is (2 °C x 4 weeks) 8 DHW. Over time, the thermal stress accumulates over a 12-week sliding window.\n\n\nReefCloud uses NOAA’s Coral Reef Watch products to provide insights on thermal stress exposure for monitored sides. NOAA’s Coral Reef Watch products are widely used and are the longest-running DHW products. For ReefCloud, we use NOAA’s Annual Maximum Degree Heating Week (DHW) indicator: For each year during 1985-2021, and at each location, NOAA provides the highest level of accumulated heat stress exposure, measured by Coral Reef Watch’s daily global 5km satellite coral bleaching DHW product. Values are derived using the Version 3.1 daily global 5km CoralTemp satellite sea surface temperature (SST) data product.\n\n\nThermal stress insights on ReefCloud are updated annually as the data becomes available on NOAA Coral Reef Watch.\n\n\nCoral bleaching and subsequent mortality related to DHW will depend on several factors, some of which are related to methodological approaches and additional external factors, as well as the inherent ecological properties of the reef at a given location. While ReefCloud provides a conservative estimation of the exposure of reef systems to thermal anomalies, the observed response to such stress may vary across locations.\nThe NOAA coral reef watch is the most widely used and longest-operating DHW product. The NOAA Coral Reef Watch program estimates the DHW from Sea Surface Temperature (SST) satellite readings at night. While a significant advantage is the validated methodology and global coverage of NOAA’s products, a key challenge with measuring water temperatures from satellites is that clouds obscure the satellite’s view, potentially resulting in large holes in the daily data. During cloudy summer wet seasons, this can result in extended periods, up to several weeks, where there are no new temperature readings, resulting in problems in the estimates of the corresponding DHW product. Hydrodynamic models paired with remotely sensed temperature can estimate temperature even during cloudy conditions. It also provides estimates of DHW at multiple depths, which is not possible with remotely sensed DHW products.\nThe bleaching response to thermal stress and subsequent mortality will also depend on the historical exposure to thermal stress in a location, additional environmental factors (e.g., Light irradiance), and the taxonomic composition of the reef in terms of the physiological susceptibility to different thermal stress thresholds. Furthermore, as reef systems get more exposed to thermal stress, research suggests that natural acclimation or adaptation of reef communities could alter the bleaching response predictions to future temperature anomalies.\n\n\n(Hoegh-Guldberg 1999; Donner 2009; Heron et al. 2016; Guest et al. 2012; Kayanne 2016; Hughes et al. 2018)\n\n\n\n\n\n\n\nIntroductionData sourceMethodsFrequency of updatesLimitations\n\n\nA tropical cyclone is a rapidly rotating storm system with low atmospheric pressure at its calm centre (eye), inward spiralling rainbands, and strong winds forming in sufficiently warm sea surface temperatures in the world’s tropical regions. In the southern hemisphere, these tropical storms are called cyclones and rotate clockwise. In contrast, in the northern hemisphere, cyclones are called hurricanes (western hemisphere) or typhoons (eastern hemisphere) and rotate in an anti-clockwise direction. If sufficiently long-lasting, the extreme winds generated by these storms can build powerful waves, severely damaging coral reefs and shorelines. By modelling where extreme waves could form during a cyclone, it is possible to predict a cyclone ‘damage zone’ beyond which major damage to reefs will not occur.  This zone is defined as the area within which the average height of the top one-third of the waves likely meets or exceeds 4 metres (Hs – significant wave height).  We call this the 4MW (Hs &gt;= 4m) zone.  Field data from 8 past cyclones in the GBR and Western Australia has shown such zones perform well at capturing severe damage – noting that because reef vulnerability is highly variable at &lt;1km scales, some parts of reefs within the damage zone will not be damaged.  Mapping the 4MW cyclone damage zone helps reef managers to:\n\nSpatially target management responses after major tropical cyclones to promote recovery at severely damaged sites.\nIdentify spatial patterns in historical tropical cyclone exposure to explain habitat condition trajectories.\n\n\n\nReefCloud aims to source the most accurate cyclone data for the impacted region. We collate data from various databases to provide the best insights possible. For cyclones within the Australian area of responsibility, we source data provided by the Australian Bureau of Meteorology’s cyclone database, while for the Pacific region, key cyclone data is sourced from the International Best Track Archive for Climate Stewardship. \n\n\nTropical cyclones are remarkably predictable and well-organised storm systems, making it possible to reconstruct the spatial distribution of winds and waves around the eye to build predicted wind and wave ‘fields’ from a short list of input data that is freely available in meteorological databases (location of eye, central and ambient air pressure, size of eye, size of cyclone and cyclone forward speed and direction).  The 4MW damage zone model (Puotinen et al. 2016) first uses this base data to reconstruct the spatial distribution of wind speeds around the cyclone eye every hour along its track.  It then searches in each location across the study area for the locations where wind speeds were sufficiently high and long-lasting to build significant wave heights &gt;= 4m, then counts the number of hours for which such conditions persisted.  The resultant 4MW cyclone damage zone predicts the locations where sufficient wave energy could cause major damage to coral reefs.  Whether or not that damage occurred for a given part of a reef in the damage zone depends on further factors that can be explored in additional work, such as how reefs and islands block the incoming waves and the structural vulnerability of the corals to wave damage.   \nThe 4MW zones provide a useful first step to reconstructing past histories of the relative impact of cyclones versus other disturbances on coral reefs (e.g., (De’ath et al. 2012; Maynard et al. 2015; Darling et al. 2019; Mellin et al. 2019; Vercelloni et al. 2020)). \nCombining the 4MW damage zones with local-scale fetch models and numerical wave models run at a coarser scale allows a more precise estimate of relative wave exposure (e.g., (Ceccarelli et al. 2019; Castro-Sanguino et al. 2021; Price et al. 2021; Gilmour et al. 2019, 2022)). \n\n\nTropical cyclone information is periodically updated once data becomes available on the key cyclone databases being used (BOM, IBTRACS).\n\n\nAs noted above, much work remains to be done to resolve damage patchiness within the 4MW damage zone (Castro-Sanguino et al. 2021). Where sufficient high-resolution bathymetry data exists with access to high-performance computing, numerical wave models can be run to better resolve local scale wave transformation (Puotinen et al. 2020; Callaghan, Mumby, and Mason 2020). Any cyclone wind or wave model is highly sensitive to the quality of the input data recorded in meteorological databases.  These datasets contain missing values and errors.  For ReefCloud, screening methods to correct some of these were implemented (for example, when the size of the eye is recorded to be larger than the size of the overall cyclone – which is impossible).  However, more work remains to be done on this.  Finally, the nature of cyclones and where they track is likely to change as the climate warms, though this remains highly uncertain for most key characteristics of cyclones (Knutson et al. 2019).  Future work will use predicted cyclone tracks from global climate models to examine how wave damage risk to reefs will change."
  },
  {
    "objectID": "Vignette_extract_RC_covariates.html#connect-to-the-geoserver",
    "href": "Vignette_extract_RC_covariates.html#connect-to-the-geoserver",
    "title": "Environmental data in ReefCloud",
    "section": "Connect to the GeoServer",
    "text": "Connect to the GeoServer\nThe code below allows you to create a connection to the server and explore the available data layers.\n\n\nCode\nlibrary(sf) # simple features packages for handling vector GIS data\nlibrary(httr) # generic webservice package\nlibrary(tidyverse) # a suite of packages for data wrangling, transformation, plotting, ...\nlibrary(ows4R) # interface for OGC webservices\nlibrary(rnaturalearth) #World Map data from Natural Earth\nlibrary(leaflet)\nlibrary(leafem)\n\n#URL for the ReefCloud GeoServer\nrc_geo&lt;-\"https://geoserver.apps.aims.gov.au/reefcloud/ows\"\n# Establish a connection\nrc_client &lt;- WFSClient$new(rc_geo, \n                           serviceVersion = \"1.0.0\")\n#List of features\nrc_client$getFeatureTypes(pretty = TRUE)\n\n\n                                                                             name\n1 reefcloud:Allen-Coral-Atlas_Great-Barrier-Reef-and-Torres-Strait-20210223210308\n2                     reefcloud:Allen-Coral-Atlas_Hawaiian-Islands-20211014191642\n3                                            reefcloud:degrees_heating_weeks_tier\n4                                        reefcloud:storm4m_exposure_cyclone_route\n5                                         reefcloud:storm4m_exposure_stormid_tier\n6                                            reefcloud:storm4m_exposure_year_tier\n7                                                     reefcloud:tmp_cyclone_route\n                                                                     title\n1 Great Barrier Reef and Torres Strait (Allen Coral Atlas -20210223210308)\n2                      Hawaiian Islands (Allen Coral Atlas-20211014191642)\n3                                               degrees_heating_weeks_tier\n4                                           storm4m_exposure_cyclone_route\n5                                            storm4m_exposure_stormid_tier\n6                                               storm4m_exposure_year_tier\n7                                                        tmp_cyclone_route\n\n\nAnother to access this information is\n\n\nCode\nknitr::opts_chunk$set(warning = FALSE, message = FALSE) \nrc_lyrs&lt;-rc_client$getFeatureTypes() %&gt;%\n  map_chr(function(x){x$getName()})"
  },
  {
    "objectID": "Vignette_extract_RC_covariates.html#request-data-for-your-monitoring-region",
    "href": "Vignette_extract_RC_covariates.html#request-data-for-your-monitoring-region",
    "title": "Environmental data in ReefCloud",
    "section": "Request data for your monitoring region",
    "text": "Request data for your monitoring region\nLet’s assume I have two monitoring sites (i.e., locations) in Palau, and I want to extract the exposure to cyclones over the years for these sites. The code below allows you to generate your sites and create a bounding box to delineate the spatial extent of your monitoring and query the GeoServer.\nI created a fake list of sites as a spatial data frame and then generated a polygon around those sites (bounding box) to query the GeoServer. Alternatively, you can use http://bboxfinder.com/ as an easy way to produce these coordinates.\n\n\nCode\nurl &lt;- parse_url(rc_geo)\n\n#Generate sites \nsites&lt;- data.frame(x=c(134.35, 134.43), y=c(7.42,7.28))%&gt;%\n  as.matrix() %&gt;%\n  st_multipoint() %&gt;% \n  st_sfc(crs=4326) %&gt;% \n  st_cast('POINT') %&gt;%\n  st_sf(name=c(\"Site1\", \"Site2\"))\n\n# create a bounding box for a spatial query.\nmy.bbox&lt;-st_bbox(st_buffer(sites,dist = 0.1))\n\nleaflet()%&gt;%addExtent(data=my.bbox,\n                        color = \"red\", \n                          stroke=T,\n                      weight = 1, \n                      smoothFactor = 0.5,\n                      opacity = 1.0, \n                      fillOpacity = 0.5,\n                      fillColor = NULL,\n                      highlightOptions = highlightOptions(color = \"white\", weight = 2,bringToFront = TRUE))%&gt;%\n  addMarkers(data=sites, label = ~name)%&gt;%\n  addProviderTiles(providers$Esri.WorldImagery)\n\n\n\n\n\n\nUsing this bounding box, we can query the server to extract the Tropical Cyclone data within this region. The table below is a simple feature data frame (spatial object) containing all the data stored in the GeoServer for Tropical Cyclone exposure within the bounding box.\n\n\nCode\n#convert bounding box into string for the query\nmy.bbox&lt;- my.bbox %&gt;%\n  as.character()%&gt;%\n  paste(.,collapse = ',')\n\n#set up your query\nurl$query &lt;- list(service = \"WFS\",\n                  version = \"1.0.0\",\n                  request = \"GetFeature\",\n                  typename = rc_lyrs[6], # I am selecting this layer:\"reefcloud:storm4m_exposure_year_tier\",\n                  bbox = my.bbox,\n                  width=768,\n                  height=330,\n                  srs=\"EPSG%3A4326\",\n                  styles='',\n                  format=\"application/openlayers\")\nrequest &lt;- build_url(url)\n\n#request the data and set up coordinate reference\npalau&lt;- read_sf(request)%&gt;%st_set_crs(4326)\n\nknitr::kable(palau %&gt;% head())\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngml_id\nstart_year\ntier\ntier_id\nmin_hrs\nmax_hrs\nend_year\nstart_date\nend_date\nstorm_count\nseverity\nstorm_list\ngeometry\n\n\n\n\nstorm4m_exposure_year_tier.1293\n2014\n4\n1870\n1\n5\n2014\n2014-04-06\n2014-04-08\n1\n1\nNA\nMULTIPOLYGON (((134.7408 7….\n\n\nstorm4m_exposure_year_tier.36549\n2021\n4\n1870\n25\n30\n2021\n2021-04-14\n2021-04-30\n1\n3\n2021102N06144\nMULTIPOLYGON (((134.7593 7….\n\n\nstorm4m_exposure_year_tier.41913\n2012\n4\n1870\n1\n5\n2012\n2012-11-27\n2012-12-08\n1\n1\n2012331N03157\nMULTIPOLYGON (((134.7079 7….\n\n\nstorm4m_exposure_year_tier.55362\n1991\n4\n1870\n10\n15\n1991\n1991-03-07\n1991-03-12\n1\n3\n1991062N04156\nMULTIPOLYGON (((134.6266 7….\n\n\nstorm4m_exposure_year_tier.55365\n1991\n4\n1871\n10\n15\n1991\n1991-03-07\n1991-03-12\n1\n3\n1991062N04156\nMULTIPOLYGON (((134.3707 6….\n\n\nstorm4m_exposure_year_tier.58954\n1990\n4\n1871\n15\n20\n1990\n1990-11-08\n1990-11-17\n1\n3\n1990310N07152\nMULTIPOLYGON (((134.4129 6….\n\n\n\n\n\nLet’s visualise the results for the year 2014 when TC Haupit impacted Palau. Note this only shows the area of interest based on the bounding box around the monitoring sites.\n\n\nCode\n#Plot results\n\ndf&lt;-palau%&gt;%dplyr::filter(start_year==2014)\npal &lt;- colorNumeric(\n  palette = \"YlOrRd\",\n  domain = df$max_hrs\n)\n\nleaflet(df)%&gt;%addPolygons(color = \"#444444\", \n                          stroke=F,\n                      weight = 1, \n                      smoothFactor = 0.5,\n                      opacity = 1.0, \n                      fillOpacity = 0.5,\n                      fillColor = ~pal(df$max_hrs),\n                      highlightOptions = highlightOptions(color = \"white\", weight = 2,bringToFront = TRUE))%&gt;%\n  addLegend(\"bottomright\", pal = pal, values = ~df$max_hrs,\n    title = \"Exposure to &lt;/br&gt; damaging waves &lt;/br&gt; (hrs)\",\n    labFormat = labelFormat(),\n    opacity = 1\n  )%&gt;%\n  addMarkers(data=sites, label = ~name)%&gt;%\n  addProviderTiles(providers$Esri.WorldImagery)"
  },
  {
    "objectID": "Vignette_extract_RC_covariates.html#extract-data-for-monitoring-sites",
    "href": "Vignette_extract_RC_covariates.html#extract-data-for-monitoring-sites",
    "title": "Environmental data in ReefCloud",
    "section": "Extract data for monitoring sites",
    "text": "Extract data for monitoring sites\nThe steps above allowed us to download the cyclone data within the bounding box. Now the data are loaded in the memory, we want to extract the specific cyclone exposure values for each site over the years. This code intercepts your sites with the environmental layer to produce tabulated data of yearly cyclone exposure at each site.\n\n\nCode\ndata = st_intersection(sites, palau)%&gt;%st_drop_geometry()%&gt;%\n  dplyr::select(name, start_year, max_hrs,min_hrs,start_date, end_date, storm_count,severity)%&gt;%\n  group_by(name, start_year)%&gt;%\n  unique()%&gt;%\n  # summarise(max_hrs=max(max_hrs), min_hrs=max(min_hrs))%&gt;%\n  arrange(name,start_year)\n  \nknitr::kable(data,format=\"html\",\n             caption=\"Table 1. Estimated cyclone impact on monitoring sites\")\n\n\n\nTable 1. Estimated cyclone impact on monitoring sites\n\n\nname\nstart_year\nmax_hrs\nmin_hrs\nstart_date\nend_date\nstorm_count\nseverity\n\n\n\n\nSite1\n1990\n25\n20\n1990-11-08\n1990-11-17\n1\n3\n\n\nSite1\n1991\n10\n5\n1991-03-07\n1991-03-12\n1\n2\n\n\nSite1\n2002\n10\n5\n2002-03-19\n2002-03-25\n1\n2\n\n\nSite1\n2012\n5\n1\n2012-11-27\n2012-12-08\n1\n1\n\n\nSite1\n2013\n5\n1\n2013-11-04\n2013-11-11\n1\n1\n\n\nSite1\n2014\n10\n5\n2014-04-06\n2014-04-08\n1\n2\n\n\nSite1\n2021\n25\n20\n2021-04-14\n2021-04-30\n1\n3\n\n\nSite2\n1990\n25\n20\n1990-11-08\n1990-11-17\n1\n3\n\n\nSite2\n1991\n10\n5\n1991-03-07\n1991-03-12\n1\n2\n\n\nSite2\n2002\n5\n1\n2002-03-19\n2002-03-25\n1\n1\n\n\nSite2\n2012\n5\n1\n2012-11-27\n2012-12-08\n1\n1\n\n\nSite2\n2014\n10\n5\n2014-04-06\n2014-04-08\n1\n2\n\n\nSite2\n2021\n25\n20\n2021-04-14\n2021-04-30\n1\n3\n\n\n\n\n\n\n\nNow, you are ready to start your analyses. Enjoy!"
  },
  {
    "objectID": "Vignette_extract_RC_covariates.html#additional-notes-for-the-data-analysis",
    "href": "Vignette_extract_RC_covariates.html#additional-notes-for-the-data-analysis",
    "title": "Environmental data in ReefCloud",
    "section": "Additional notes for the data analysis",
    "text": "Additional notes for the data analysis\n\nThermal Stress and Tropical Cyclones are discrete events. This means they happen during a relatively short period in a year. Similarly, monitoring observations are discrete, and they accumulate over the years. When analysing monitoring data and the correlation of response variables (e.g., coral cover) to the incidence of disturbances (e.g., cyclones), please note the disturbances’ start and end dates to appropriately assess a disturbance to an observation. For example, if you are monitoring a reef just before a cyclone happened but modelled coral cover over time using discrete years, assigning the cyclone exposure to that monitoring year will not capture the impact of the disturbance on the response variable.\nIt may be helpful to consider that many large-scale and intense disturbances tend to have a lag effect on coral reef benthos over the years ([Castro-Sanguino et al. (2021)](Cheal et al. 2017)).\nPlease review the limitations section for each of the datasets. Note that the spatial resolution of these variables is limited compared to monitoring data. Therefore, caution should be exercised when interpreting the results of correlative statistics."
  },
  {
    "objectID": "Collection.html#manage-and-map-labelsets-taxonomy",
    "href": "Collection.html#manage-and-map-labelsets-taxonomy",
    "title": "How-to",
    "section": "Manage and Map Labelsets (Taxonomy)",
    "text": "Manage and Map Labelsets (Taxonomy)"
  },
  {
    "objectID": "Collection.html#add-and-manage-sites",
    "href": "Collection.html#add-and-manage-sites",
    "title": "How-to",
    "section": "Add and Manage Sites",
    "text": "Add and Manage Sites"
  },
  {
    "objectID": "Collection.html#add-and-manage-survey-images",
    "href": "Collection.html#add-and-manage-survey-images",
    "title": "How-to",
    "section": "Add and Manage Survey images",
    "text": "Add and Manage Survey images"
  },
  {
    "objectID": "Collection.html#view-enable-disable-and-delete-images",
    "href": "Collection.html#view-enable-disable-and-delete-images",
    "title": "How-to",
    "section": "View, Enable, Disable and Delete Images",
    "text": "View, Enable, Disable and Delete Images"
  },
  {
    "objectID": "Collection.html#classify-images",
    "href": "Collection.html#classify-images",
    "title": "How-to",
    "section": "Classify Images",
    "text": "Classify Images"
  },
  {
    "objectID": "Collection.html#interpret-ai-results",
    "href": "Collection.html#interpret-ai-results",
    "title": "How-to",
    "section": "Interpret AI results",
    "text": "Interpret AI results"
  },
  {
    "objectID": "Collection.html#export-your-data",
    "href": "Collection.html#export-your-data",
    "title": "How-to",
    "section": "Export your data",
    "text": "Export your data"
  },
  {
    "objectID": "How-to.html",
    "href": "How-to.html",
    "title": "How-to",
    "section": "",
    "text": "Here you will find a series of short videos to guide you on “how to” do specific tasks in ReefCloud. Use the menu bar on the right or the searching function at the top to explore the topics we have prepared for you. They are organised sequentially, from getting started as a new user in ReefCloud, to managing your survey data, utilising AI for annotating your images, and exporting your results.\nIf you would like to see additional topics added to this list, please let us know at reefcloud@aims.gov.au."
  },
  {
    "objectID": "How-to.html#create-a-user-account",
    "href": "How-to.html#create-a-user-account",
    "title": "How-to",
    "section": "Create a User Account",
    "text": "Create a User Account"
  },
  {
    "objectID": "How-to.html#create-a-new-project",
    "href": "How-to.html#create-a-new-project",
    "title": "How-to",
    "section": "Create a New Project",
    "text": "Create a New Project"
  },
  {
    "objectID": "How-to.html#add-users-and-manage-project-permissions",
    "href": "How-to.html#add-users-and-manage-project-permissions",
    "title": "How-to",
    "section": "Add Users and Manage Project Permissions",
    "text": "Add Users and Manage Project Permissions"
  },
  {
    "objectID": "How-to.html#manage-and-map-labelsets-taxonomy",
    "href": "How-to.html#manage-and-map-labelsets-taxonomy",
    "title": "How-to",
    "section": "Manage and Map Labelsets (Taxonomy)",
    "text": "Manage and Map Labelsets (Taxonomy)"
  },
  {
    "objectID": "How-to.html#add-and-manage-sites",
    "href": "How-to.html#add-and-manage-sites",
    "title": "How-to",
    "section": "Add and Manage Sites",
    "text": "Add and Manage Sites"
  },
  {
    "objectID": "How-to.html#add-and-manage-survey-images",
    "href": "How-to.html#add-and-manage-survey-images",
    "title": "How-to",
    "section": "Add and Manage Survey images",
    "text": "Add and Manage Survey images"
  },
  {
    "objectID": "How-to.html#view-enable-disable-and-delete-images",
    "href": "How-to.html#view-enable-disable-and-delete-images",
    "title": "How-to",
    "section": "View, Enable, Disable, and Delete Images",
    "text": "View, Enable, Disable, and Delete Images"
  },
  {
    "objectID": "How-to.html#classify-images",
    "href": "How-to.html#classify-images",
    "title": "How-to",
    "section": "Classify Images",
    "text": "Classify Images"
  },
  {
    "objectID": "How-to.html#interpret-ai-results",
    "href": "How-to.html#interpret-ai-results",
    "title": "How-to",
    "section": "Interpret AI results",
    "text": "Interpret AI results"
  },
  {
    "objectID": "How-to.html#export-your-data",
    "href": "How-to.html#export-your-data",
    "title": "How-to",
    "section": "Export your data",
    "text": "Export your data"
  },
  {
    "objectID": "Analyses.html#r-basics",
    "href": "Analyses.html#r-basics",
    "title": "Data Analyses in R",
    "section": "R basics",
    "text": "R basics\n\nIntroduction to R\nSelecting your Code Editor\nManaging data in R\nData wrangling\nIntroduction to Graphs"
  },
  {
    "objectID": "Analyses.html#reproducible-research",
    "href": "Analyses.html#reproducible-research",
    "title": "Data Analyses in R",
    "section": "Reproducible research",
    "text": "Reproducible research\n\nIntroduction to Version Control"
  },
  {
    "objectID": "index2.html",
    "href": "index2.html",
    "title": "Resources",
    "section": "",
    "text": "Overview\n\n\n\nA brief video introduction to walk you through the ReefCloud features from start to end\n\n\nRead more\n\n\n\n\n\n\n\n\nCollecting photos\n\n\n\nA methodological guide you on designing your monitoring program and collecting data to analyse in ReefCloud\n\n\nComing Soon\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing ReefCloud\n\n\n\nA step-by-step guide to using ReefCloud for analysing coral reef monitoring data\n\n\nRead more\n\n\n\n\n\n\n\nVideo Resources\n\n\n\nA collection of short videos to guide you on how to perform specific tasks in ReefCloud\n\n\nRead more\n\n\n\n\n\n\n\n\n\n\n\n\n\nFAQs\n\n\n\nFrequently Asked Questions about ReefCloud\n\n\nComing Soon\n\n\n\n\n\n\n\n\n\n\nData Analysis in R\n\n\n\nTutorials and code snippets to guide you, step-by-step, on monitoring data analyses using R language.\n\n\nRead more"
  },
  {
    "objectID": "docs/docs/docs/gitbook/planning-your-surveys.html",
    "href": "docs/docs/docs/gitbook/planning-your-surveys.html",
    "title": "Planning your Surveys",
    "section": "",
    "text": "Planning your Surveys\nThere are many steps involved in planning and the initial and most important is defining a research question(s) and identifying the indicators the survey(s) will collect. \nOnce a sampling design is developed, a sampling criterion on selecting sites can be derived by:\n\nThe types of habitats to target to data collection;\nThe number of sites within each habitat;\nThe length of transects and number of transects per site so you know how much reef areas is needed for survey.\nThe target reef zones;\nSites close to population centres or rivers; and\nThe indicators that the survey has targeted.\n\nThe next step would be to mark sites on the map and extract GPS coordinates for the survey. There are two ways of getting a better understanding of the reef system, (1) conducting a scoping survey of the area(s) on techniques like manta tow and (2) using habitat or details feature maps such as Google Earth (https://shorturl.at/brGIU), Allen Coral Atlas (https://allencoralatlas.org/), using the sampling criteria to select sites. Additionally, a local tide chart and weather bulletin is also important to develop a daily workplan."
  },
  {
    "objectID": "docs/docs/docs/gitbook/representation-and-replication-in-sampling-design.html",
    "href": "docs/docs/docs/gitbook/representation-and-replication-in-sampling-design.html",
    "title": "Representation and replication in sampling design",
    "section": "",
    "text": "Representation and replication in sampling design\nSampling design and strategies are a way of capturing the right kind of information using the best techniques without surveying every single habitat across large areas. The sampling design focuses on capturing the state and processes that vary from location to location, at a spatial scale of large areas and over time. Some key considerations for sampling design include:\n\nSix to seven sites per location.\nSystematic selection of sites based on depth.\nSites should be spaced out along the reef (~ 1-2 km apart).\nSome random stations can be selected within sites to represent the area surveyed.\nAny historical data site should be incorporated into the design.\nThe site should be representative of the habitat of interest so summary information provides an average of different habitats and is not biased towards one or two habitats.\nThe size of a sampling unit/area (size of the quadrat or photo frame), the variability of habitats, and the overall size of reefs should be considered during the design phase.\nSites would have multiple replicates (transects or surveys as identified in ReefCloud). Having replicates within sites minimises the influence of variability to some extent that is caused by small-scale differences in the reef structure, observer bias and inconsistency in data collection technique. Data for each site is an average of all the transects/surveys combined or the changes in each transect/survey can be monitored over time if they are conducted in the same geo-referenced area.\n\nNote: Details on sampling design and site selection for coral reef monitoring in discussed in the module on sampling design and site selection."
  },
  {
    "objectID": "docs/docs/docs/gitbook/selecting-the-most-appropriate-coral-survey-method..html",
    "href": "docs/docs/docs/gitbook/selecting-the-most-appropriate-coral-survey-method..html",
    "title": "Selecting the most appropriate coral survey method.",
    "section": "",
    "text": "Selecting the most appropriate coral survey method.\nThere are various sampling methods used for coral reef surveys. Some methods are specific for certain types of data collection while others are more widely used for general observation. Methods range from large-scale data coral reef surveys to area-specific surveys designed to answer specific questions. The most common coral reef survey methods can be divided into two categories, in-situ diver surveys and diver surveys using technology for data collection.\nThe methods will also depend on the expertise of the team, site accessibility, availability of equipment, budget, and time. \nMore information on the survey methods can be found in the appendix: Coral Reef Survey Methods."
  },
  {
    "objectID": "docs/docs/docs/gitbook/site-selection.html",
    "href": "docs/docs/docs/gitbook/site-selection.html",
    "title": "Site selection",
    "section": "",
    "text": "Site selection\nThe sites selection process is divided into two parts defined by the questions such as:\n\nIs this the first time we are surveys these reefs?\nIf no, who has existing data and sites coordinates?\nAre we surveying the same sites or do we need new sites or a combination to meet collect the types of data required.\nWhat is the depth range targeted for this survey?\nHow many days do we need to survey all sites?\nIf the weather is not favourable or there are some unforeseen circumstances, how many sites should be targeted to complete within the timeframe?\nIf such conditions occur, what is the trade-off between reducing the number of sites verse number of transect?\n\nExisting monitoring sites\nWhile working with existing monitoring sites it is recommended that:\n\nUse the coordinates to plot the sites on a map (you can use the mapping options in section 5.2.1).\nIdentify sites that are absolutely needed and sites that can be optional;\nIs there a need to conduct surveys at all existing monitoring sites or do we need some new sites to answer the question(s);\nRank the existing sites from high to low priority; and\nIf needed, add the new sites coordinates.\nOnce the sites have been prioritised, the coordinates for the sites (waypoints) can be extracted and entered into a handheld GPS to locate sites during surveys (if not in the GPS).\n\nNote: Local weather conditions, the number of days allocated for surveys and the level of comfort and expertise in the team are also important to consider for logistics and to safely conduct surveys.\n\nSelecting new sites.\nWhen working in areas never surveyed before or have no record of any data collection, the steps include:\n\nGathering as much information as possible about the areas from locals and online sources. The types if information that are required for planning are dangerous animals, currents and currents, accessibility to sites, availability of boats, distance from mainland, boat guide with a good understanding of local conditions.\nReviewing/exploring maps with local knowledge to identify areas that you may want to survey. If possible, use a map with more detailed features such as Allen Coral Atlas (allencoralatlas.org) to understand the diversity of the reef system. This will assist with the site selection process by providing guidance towards target habitats, the estimated size and accessibility of reefs and the likelihood of finding the target habitats in the areas.\nOnce the habitats have been identified, plot the sites on the map and rank them from high to low priority.\nThe number of days allocated for surveys and the weather conditions play an important role in sites prioritisation process.\nOnce the sites have been prioritised, the coordinates for the sites (waypoints) can be extracted and entered into a handheld GPS to locate sites during surveys.\n\n![A diagram of a land layer\nDescription automatically generated with medium confidence](../../.gitbook/assets/2.png)\nNote: The site selected for monitoring should be representative of the area of interest and contain the same habitats so comparable data can be gathered from different sites (2004 Hill and Wilkson)"
  },
  {
    "objectID": "docs/docs/gitbook/planning-your-surveys.html",
    "href": "docs/docs/gitbook/planning-your-surveys.html",
    "title": "Planning your Surveys",
    "section": "",
    "text": "Planning your Surveys\nThere are many steps involved in planning and the initial and most important is defining a research question(s) and identifying the indicators the survey(s) will collect. \nOnce a sampling design is developed, a sampling criterion on selecting sites can be derived by:\n\nThe types of habitats to target to data collection;\nThe number of sites within each habitat;\nThe length of transects and number of transects per site so you know how much reef areas is needed for survey.\nThe target reef zones;\nSites close to population centres or rivers; and\nThe indicators that the survey has targeted.\n\nThe next step would be to mark sites on the map and extract GPS coordinates for the survey. There are two ways of getting a better understanding of the reef system, (1) conducting a scoping survey of the area(s) on techniques like manta tow and (2) using habitat or details feature maps such as Google Earth (https://shorturl.at/brGIU), Allen Coral Atlas (https://allencoralatlas.org/), using the sampling criteria to select sites. Additionally, a local tide chart and weather bulletin is also important to develop a daily workplan."
  },
  {
    "objectID": "docs/docs/gitbook/representation-and-replication-in-sampling-design.html",
    "href": "docs/docs/gitbook/representation-and-replication-in-sampling-design.html",
    "title": "Representation and replication in sampling design",
    "section": "",
    "text": "Representation and replication in sampling design\nSampling design and strategies are a way of capturing the right kind of information using the best techniques without surveying every single habitat across large areas. The sampling design focuses on capturing the state and processes that vary from location to location, at a spatial scale of large areas and over time. Some key considerations for sampling design include:\n\nSix to seven sites per location.\nSystematic selection of sites based on depth.\nSites should be spaced out along the reef (~ 1-2 km apart).\nSome random stations can be selected within sites to represent the area surveyed.\nAny historical data site should be incorporated into the design.\nThe site should be representative of the habitat of interest so summary information provides an average of different habitats and is not biased towards one or two habitats.\nThe size of a sampling unit/area (size of the quadrat or photo frame), the variability of habitats, and the overall size of reefs should be considered during the design phase.\nSites would have multiple replicates (transects or surveys as identified in ReefCloud). Having replicates within sites minimises the influence of variability to some extent that is caused by small-scale differences in the reef structure, observer bias and inconsistency in data collection technique. Data for each site is an average of all the transects/surveys combined or the changes in each transect/survey can be monitored over time if they are conducted in the same geo-referenced area.\n\nNote: Details on sampling design and site selection for coral reef monitoring in discussed in the module on sampling design and site selection."
  },
  {
    "objectID": "docs/docs/gitbook/selecting-the-most-appropriate-coral-survey-method..html",
    "href": "docs/docs/gitbook/selecting-the-most-appropriate-coral-survey-method..html",
    "title": "Selecting the most appropriate coral survey method.",
    "section": "",
    "text": "Selecting the most appropriate coral survey method.\nThere are various sampling methods used for coral reef surveys. Some methods are specific for certain types of data collection while others are more widely used for general observation. Methods range from large-scale data coral reef surveys to area-specific surveys designed to answer specific questions. The most common coral reef survey methods can be divided into two categories, in-situ diver surveys and diver surveys using technology for data collection.\nThe methods will also depend on the expertise of the team, site accessibility, availability of equipment, budget, and time. \nMore information on the survey methods can be found in the appendix: Coral Reef Survey Methods."
  },
  {
    "objectID": "docs/docs/gitbook/site-selection.html",
    "href": "docs/docs/gitbook/site-selection.html",
    "title": "Site selection",
    "section": "",
    "text": "Site selection\nThe sites selection process is divided into two parts defined by the questions such as:\n\nIs this the first time we are surveys these reefs?\nIf no, who has existing data and sites coordinates?\nAre we surveying the same sites or do we need new sites or a combination to meet collect the types of data required.\nWhat is the depth range targeted for this survey?\nHow many days do we need to survey all sites?\nIf the weather is not favourable or there are some unforeseen circumstances, how many sites should be targeted to complete within the timeframe?\nIf such conditions occur, what is the trade-off between reducing the number of sites verse number of transect?\n\nExisting monitoring sites\nWhile working with existing monitoring sites it is recommended that:\n\nUse the coordinates to plot the sites on a map (you can use the mapping options in section 5.2.1).\nIdentify sites that are absolutely needed and sites that can be optional;\nIs there a need to conduct surveys at all existing monitoring sites or do we need some new sites to answer the question(s);\nRank the existing sites from high to low priority; and\nIf needed, add the new sites coordinates.\nOnce the sites have been prioritised, the coordinates for the sites (waypoints) can be extracted and entered into a handheld GPS to locate sites during surveys (if not in the GPS).\n\nNote: Local weather conditions, the number of days allocated for surveys and the level of comfort and expertise in the team are also important to consider for logistics and to safely conduct surveys.\n\nSelecting new sites.\nWhen working in areas never surveyed before or have no record of any data collection, the steps include:\n\nGathering as much information as possible about the areas from locals and online sources. The types if information that are required for planning are dangerous animals, currents and currents, accessibility to sites, availability of boats, distance from mainland, boat guide with a good understanding of local conditions.\nReviewing/exploring maps with local knowledge to identify areas that you may want to survey. If possible, use a map with more detailed features such as Allen Coral Atlas (allencoralatlas.org) to understand the diversity of the reef system. This will assist with the site selection process by providing guidance towards target habitats, the estimated size and accessibility of reefs and the likelihood of finding the target habitats in the areas.\nOnce the habitats have been identified, plot the sites on the map and rank them from high to low priority.\nThe number of days allocated for surveys and the weather conditions play an important role in sites prioritisation process.\nOnce the sites have been prioritised, the coordinates for the sites (waypoints) can be extracted and entered into a handheld GPS to locate sites during surveys.\n\n![A diagram of a land layer\nDescription automatically generated with medium confidence](../../.gitbook/assets/2.png)\nNote: The site selected for monitoring should be representative of the area of interest and contain the same habitats so comparable data can be gathered from different sites (2004 Hill and Wilkson)"
  },
  {
    "objectID": "docs/gitbook/planning-your-surveys.html",
    "href": "docs/gitbook/planning-your-surveys.html",
    "title": "Planning your Surveys",
    "section": "",
    "text": "Planning your Surveys\nThere are many steps involved in planning and the initial and most important is defining a research question(s) and identifying the indicators the survey(s) will collect. \nOnce a sampling design is developed, a sampling criterion on selecting sites can be derived by:\n\nThe types of habitats to target to data collection;\nThe number of sites within each habitat;\nThe length of transects and number of transects per site so you know how much reef areas is needed for survey.\nThe target reef zones;\nSites close to population centres or rivers; and\nThe indicators that the survey has targeted.\n\nThe next step would be to mark sites on the map and extract GPS coordinates for the survey. There are two ways of getting a better understanding of the reef system, (1) conducting a scoping survey of the area(s) on techniques like manta tow and (2) using habitat or details feature maps such as Google Earth (https://shorturl.at/brGIU), Allen Coral Atlas (https://allencoralatlas.org/), using the sampling criteria to select sites. Additionally, a local tide chart and weather bulletin is also important to develop a daily workplan."
  },
  {
    "objectID": "docs/gitbook/representation-and-replication-in-sampling-design.html",
    "href": "docs/gitbook/representation-and-replication-in-sampling-design.html",
    "title": "Representation and replication in sampling design",
    "section": "",
    "text": "Representation and replication in sampling design\nSampling design and strategies are a way of capturing the right kind of information using the best techniques without surveying every single habitat across large areas. The sampling design focuses on capturing the state and processes that vary from location to location, at a spatial scale of large areas and over time. Some key considerations for sampling design include:\n\nSix to seven sites per location.\nSystematic selection of sites based on depth.\nSites should be spaced out along the reef (~ 1-2 km apart).\nSome random stations can be selected within sites to represent the area surveyed.\nAny historical data site should be incorporated into the design.\nThe site should be representative of the habitat of interest so summary information provides an average of different habitats and is not biased towards one or two habitats.\nThe size of a sampling unit/area (size of the quadrat or photo frame), the variability of habitats, and the overall size of reefs should be considered during the design phase.\nSites would have multiple replicates (transects or surveys as identified in ReefCloud). Having replicates within sites minimises the influence of variability to some extent that is caused by small-scale differences in the reef structure, observer bias and inconsistency in data collection technique. Data for each site is an average of all the transects/surveys combined or the changes in each transect/survey can be monitored over time if they are conducted in the same geo-referenced area.\n\nNote: Details on sampling design and site selection for coral reef monitoring in discussed in the module on sampling design and site selection."
  },
  {
    "objectID": "docs/gitbook/selecting-the-most-appropriate-coral-survey-method..html",
    "href": "docs/gitbook/selecting-the-most-appropriate-coral-survey-method..html",
    "title": "Selecting the most appropriate coral survey method.",
    "section": "",
    "text": "Selecting the most appropriate coral survey method.\nThere are various sampling methods used for coral reef surveys. Some methods are specific for certain types of data collection while others are more widely used for general observation. Methods range from large-scale data coral reef surveys to area-specific surveys designed to answer specific questions. The most common coral reef survey methods can be divided into two categories, in-situ diver surveys and diver surveys using technology for data collection.\nThe methods will also depend on the expertise of the team, site accessibility, availability of equipment, budget, and time. \nMore information on the survey methods can be found in the appendix: Coral Reef Survey Methods."
  },
  {
    "objectID": "docs/gitbook/site-selection.html",
    "href": "docs/gitbook/site-selection.html",
    "title": "Site selection",
    "section": "",
    "text": "Site selection\nThe sites selection process is divided into two parts defined by the questions such as:\n\nIs this the first time we are surveys these reefs?\nIf no, who has existing data and sites coordinates?\nAre we surveying the same sites or do we need new sites or a combination to meet collect the types of data required.\nWhat is the depth range targeted for this survey?\nHow many days do we need to survey all sites?\nIf the weather is not favourable or there are some unforeseen circumstances, how many sites should be targeted to complete within the timeframe?\nIf such conditions occur, what is the trade-off between reducing the number of sites verse number of transect?\n\nExisting monitoring sites\nWhile working with existing monitoring sites it is recommended that:\n\nUse the coordinates to plot the sites on a map (you can use the mapping options in section 5.2.1).\nIdentify sites that are absolutely needed and sites that can be optional;\nIs there a need to conduct surveys at all existing monitoring sites or do we need some new sites to answer the question(s);\nRank the existing sites from high to low priority; and\nIf needed, add the new sites coordinates.\nOnce the sites have been prioritised, the coordinates for the sites (waypoints) can be extracted and entered into a handheld GPS to locate sites during surveys (if not in the GPS).\n\nNote: Local weather conditions, the number of days allocated for surveys and the level of comfort and expertise in the team are also important to consider for logistics and to safely conduct surveys.\n\nSelecting new sites.\nWhen working in areas never surveyed before or have no record of any data collection, the steps include:\n\nGathering as much information as possible about the areas from locals and online sources. The types if information that are required for planning are dangerous animals, currents and currents, accessibility to sites, availability of boats, distance from mainland, boat guide with a good understanding of local conditions.\nReviewing/exploring maps with local knowledge to identify areas that you may want to survey. If possible, use a map with more detailed features such as Allen Coral Atlas (allencoralatlas.org) to understand the diversity of the reef system. This will assist with the site selection process by providing guidance towards target habitats, the estimated size and accessibility of reefs and the likelihood of finding the target habitats in the areas.\nOnce the habitats have been identified, plot the sites on the map and rank them from high to low priority.\nThe number of days allocated for surveys and the weather conditions play an important role in sites prioritisation process.\nOnce the sites have been prioritised, the coordinates for the sites (waypoints) can be extracted and entered into a handheld GPS to locate sites during surveys.\n\n![A diagram of a land layer\nDescription automatically generated with medium confidence](../../.gitbook/assets/2.png)\nNote: The site selected for monitoring should be representative of the area of interest and contain the same habitats so comparable data can be gathered from different sites (2004 Hill and Wilkson)"
  },
  {
    "objectID": "Vignette_generate_CM.html",
    "href": "Vignette_generate_CM.html",
    "title": "Calculate Confusion mAtrix from ReefCloud’s export",
    "section": "",
    "text": "Import Data\n\nlibrary(caret)\n\nWarning: package 'caret' was built under R version 4.2.3\n\n\nLoading required package: ggplot2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nLoading required package: lattice\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.3\n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\nWarning: package 'purrr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.2.3\n\n\nWarning: package 'forcats' was built under R version 4.2.3\n\n\nWarning: package 'lubridate' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.1     ✔ tidyr     1.3.0\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ purrr::lift()   masks caret::lift()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndf&lt;-read.csv2(\"C://Users/mgonzale/Downloads/reefcloud-point-classification-nha-trang-vietnam-coral-reef-monitoring-2024-2024-04-10.csv\", sep=\",\")%&gt;%\n  filter(point_human_classification!=\"\")\n\nCalculate the Confusion Matrix"
  },
  {
    "objectID": "Vignette_generate_CM.html#set-up",
    "href": "Vignette_generate_CM.html#set-up",
    "title": "Calculate Confusion mAtrix from ReefCloud’s export",
    "section": "",
    "text": "Import Data\n\nlibrary(caret)\n\nWarning: package 'caret' was built under R version 4.2.3\n\n\nLoading required package: ggplot2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nLoading required package: lattice\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.3\n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\nWarning: package 'purrr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.2.3\n\n\nWarning: package 'forcats' was built under R version 4.2.3\n\n\nWarning: package 'lubridate' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.1     ✔ tidyr     1.3.0\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ purrr::lift()   masks caret::lift()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndf&lt;-read.csv2(\"C://Users/mgonzale/Downloads/reefcloud-point-classification-nha-trang-vietnam-coral-reef-monitoring-2024-2024-04-10.csv\", sep=\",\")%&gt;%\n  filter(point_human_classification!=\"\")\n\nCalculate the Confusion Matrix"
  },
  {
    "objectID": "Vignette_generate_CM.html#plot",
    "href": "Vignette_generate_CM.html#plot",
    "title": "Calculate Confusion mAtrix from ReefCloud’s export",
    "section": "Plot",
    "text": "Plot\n\nheatmap(cm.1$table, \n        main = \"Confusion Matrix\",\n        xlab = \"Predicted\",\n        ylab = \"Actual\",\n        col = heat.colors(10),\n        scale = \"column\",\n        margins = c(5, 5))"
  },
  {
    "objectID": "index_old.html",
    "href": "index_old.html",
    "title": "About this page",
    "section": "",
    "text": "This site is a constantly evolving repository where you can find a range of resources to maximise your experience with ReefCloud. This includes supporting documents, materials and coding resources for benthic coral reef monitoring and reporting using ReefCloud as the engine room.\nFor more documentation about how to use ReefCloud, check out our User Documentation.\n\n\n\nHow-to videos\nR code examples\nTemplates\nPresentations"
  },
  {
    "objectID": "index_old.html#here-you-can-find",
    "href": "index_old.html#here-you-can-find",
    "title": "About this page",
    "section": "",
    "text": "How-to videos\nR code examples\nTemplates\nPresentations"
  },
  {
    "objectID": "ReefCloud_Overview.html",
    "href": "ReefCloud_Overview.html",
    "title": "About ReefCloud",
    "section": "",
    "text": "ReefCloud is an open-access data platform designed to quickly and efficiently collate and analyse monitoring data to automate report on the status and trends of coral reefs worldwide.\nThis sites contains a constantly evolving repository with a range of resources to maximise your experience with ReefCloud. This includes supporting documents, materials and coding resources for benthic coral reef monitoring and reporting using ReefCloud as the engine room.\nAs a way of introduction, the video below walk you through ReefCloud and its main features, while pointing to training resources.\nPlease reach out to us at support@reefcloud.ai if you have any questions or suggestions."
  },
  {
    "objectID": "Use-RC.html",
    "href": "Use-RC.html",
    "title": "Using ReefCloud",
    "section": "",
    "text": "Here, you will find a series of resources that will help you make the most of ReefCloud. Use the menu bar on the right or the searching function at the top to explore the topics we have prepared for you.\nIf you want additional topics added to this list, please let us know at reefcloud@aims.gov.au."
  },
  {
    "objectID": "Use-RC.html#create-a-user-account",
    "href": "Use-RC.html#create-a-user-account",
    "title": "How-to",
    "section": "Create a User Account",
    "text": "Create a User Account"
  },
  {
    "objectID": "Use-RC.html#create-a-new-project",
    "href": "Use-RC.html#create-a-new-project",
    "title": "How-to",
    "section": "Create a New Project",
    "text": "Create a New Project"
  },
  {
    "objectID": "Use-RC.html#add-users-and-manage-project-permissions",
    "href": "Use-RC.html#add-users-and-manage-project-permissions",
    "title": "How-to",
    "section": "Add Users and Manage Project Permissions",
    "text": "Add Users and Manage Project Permissions"
  },
  {
    "objectID": "Use-RC.html#manage-and-map-labelsets-taxonomy",
    "href": "Use-RC.html#manage-and-map-labelsets-taxonomy",
    "title": "How-to",
    "section": "Manage and Map Labelsets (Taxonomy)",
    "text": "Manage and Map Labelsets (Taxonomy)"
  },
  {
    "objectID": "Use-RC.html#add-and-manage-sites",
    "href": "Use-RC.html#add-and-manage-sites",
    "title": "How-to",
    "section": "Add and Manage Sites",
    "text": "Add and Manage Sites"
  },
  {
    "objectID": "Use-RC.html#add-and-manage-survey-images",
    "href": "Use-RC.html#add-and-manage-survey-images",
    "title": "How-to",
    "section": "Add and Manage Survey images",
    "text": "Add and Manage Survey images"
  },
  {
    "objectID": "Use-RC.html#view-enable-disable-and-delete-images",
    "href": "Use-RC.html#view-enable-disable-and-delete-images",
    "title": "How-to",
    "section": "View, Enable, Disable, and Delete Images",
    "text": "View, Enable, Disable, and Delete Images"
  },
  {
    "objectID": "Use-RC.html#classify-images",
    "href": "Use-RC.html#classify-images",
    "title": "How-to",
    "section": "Classify Images",
    "text": "Classify Images"
  },
  {
    "objectID": "Use-RC.html#interpret-ai-results",
    "href": "Use-RC.html#interpret-ai-results",
    "title": "How-to",
    "section": "Interpret AI results",
    "text": "Interpret AI results"
  },
  {
    "objectID": "Use-RC.html#export-your-data",
    "href": "Use-RC.html#export-your-data",
    "title": "How-to",
    "section": "Export your data",
    "text": "Export your data"
  },
  {
    "objectID": "Use-RC.html#user-manuals",
    "href": "Use-RC.html#user-manuals",
    "title": "Using ReefCloud",
    "section": "User Manuals",
    "text": "User Manuals\n\nBrief Introductory Manual\nDetailed User Manual"
  }
]